{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "import autograd.scipy as sp\n",
    "import autograd.misc.optimizers\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward:\n",
    "    def __init__(self, architecture, random=None, weights=None):\n",
    "        self.params = {'H': architecture['width'],\n",
    "                       'L': architecture['hidden_layers'],\n",
    "                       'D_in': architecture['input_dim'],\n",
    "                       'D_out': architecture['output_dim'],\n",
    "                       'activation_type': architecture['activation_fn_type'],\n",
    "                       'activation_params': architecture['activation_fn_params']}\n",
    "\n",
    "        self.D = (  (architecture['input_dim'] * architecture['width'] + architecture['width'])\n",
    "                  + (architecture['output_dim'] * architecture['width'] + architecture['output_dim'])\n",
    "                  + (architecture['hidden_layers'] - 1) * (architecture['width']**2 + architecture['width'])\n",
    "                 )\n",
    "\n",
    "        if random is not None:\n",
    "            self.random = random\n",
    "        else:\n",
    "            self.random = np.random.RandomState(0)\n",
    "\n",
    "        self.h = architecture['activation_fn']\n",
    "\n",
    "        if weights is None:\n",
    "            self.weights = self.random.normal(0, 1, size=(1, self.D))\n",
    "        else:\n",
    "            self.weights = weights\n",
    "\n",
    "        self.objective_trace = np.empty((1, 1))\n",
    "        self.weight_trace = np.empty((1, self.D))\n",
    "\n",
    "\n",
    "    def forward(self, weights, x):\n",
    "        ''' Forward pass given weights and input '''\n",
    "        H = self.params['H']\n",
    "        D_in = self.params['D_in']\n",
    "        D_out = self.params['D_out']\n",
    "\n",
    "        assert weights.shape[1] == self.D\n",
    "\n",
    "        if len(x.shape) == 2:\n",
    "            assert x.shape[0] == D_in\n",
    "            x = x.reshape((1, D_in, -1))\n",
    "        else:\n",
    "            assert x.shape[1] == D_in\n",
    "\n",
    "        weights = weights.T\n",
    "\n",
    "\n",
    "        #input to first hidden layer\n",
    "        W = weights[:H * D_in].T.reshape((-1, H, D_in))\n",
    "        b = weights[H * D_in:H * D_in + H].T.reshape((-1, H, 1))\n",
    "        input = self.h(np.matmul(W, x) + b)\n",
    "        index = H * D_in + H\n",
    "\n",
    "        assert input.shape[1] == H\n",
    "\n",
    "        #additional hidden layers\n",
    "        for _ in range(self.params['L'] - 1):\n",
    "            before = index\n",
    "            W = weights[index:index + H * H].T.reshape((-1, H, H))\n",
    "            index += H * H\n",
    "            b = weights[index:index + H].T.reshape((-1, H, 1))\n",
    "            index += H\n",
    "            output = np.matmul(W, input) + b\n",
    "            input = self.h(output)\n",
    "\n",
    "            assert input.shape[1] == H\n",
    "\n",
    "        #output layer\n",
    "        W = weights[index:index + H * D_out].T.reshape((-1, D_out, H))\n",
    "        b = weights[index + H * D_out:].T.reshape((-1, D_out, 1))\n",
    "        output = np.matmul(W, input) + b\n",
    "        assert output.shape[1] == self.params['D_out']\n",
    "\n",
    "        return output\n",
    "\n",
    "    def make_objective(self, x_train, y_train, reg_param=None):\n",
    "        ''' Make objective functions: depending on whether or not you want to apply l2 regularization '''\n",
    "        \n",
    "        if reg_param is None:\n",
    "            \n",
    "            def objective(W, t):\n",
    "                squared_error = np.linalg.norm(y_train - self.forward(W, x_train), axis=1)**2\n",
    "                sum_error = np.sum(squared_error)\n",
    "                return sum_error\n",
    "            \n",
    "            return objective, autograd.grad(objective)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            def objective(W, t):\n",
    "                squared_error = np.linalg.norm(y_train - self.forward(W, x_train), axis=1)**2\n",
    "                mean_error = np.mean(squared_error) + reg_param * np.linalg.norm(W)\n",
    "                return mean_error\n",
    "            \n",
    "            return objective, autograd.grad(objective)\n",
    "\n",
    "    def fit(self, x_train, y_train, params, reg_param=None):\n",
    "        ''' Wrapper for MLE through gradient descent '''\n",
    "        assert x_train.shape[0] == self.params['D_in']\n",
    "        assert y_train.shape[0] == self.params['D_out']\n",
    "\n",
    "        ### make objective function for training\n",
    "        self.objective, self.gradient = self.make_objective(x_train, y_train, reg_param)\n",
    "\n",
    "        ### set up optimization\n",
    "        step_size = 0.01\n",
    "        max_iteration = 5000\n",
    "        check_point = 100\n",
    "        weights_init = self.weights.reshape((1, -1))\n",
    "        mass = None\n",
    "        optimizer = 'adam'\n",
    "        random_restarts = 5\n",
    "\n",
    "        if 'step_size' in params.keys():\n",
    "            step_size = params['step_size']\n",
    "        if 'max_iteration' in params.keys():\n",
    "            max_iteration = params['max_iteration']\n",
    "        if 'check_point' in params.keys():\n",
    "            self.check_point = params['check_point']\n",
    "        if 'init' in params.keys():\n",
    "            weights_init = params['init']\n",
    "        if 'call_back' in params.keys():\n",
    "            call_back = params['call_back']\n",
    "        if 'mass' in params.keys():\n",
    "            mass = params['mass']\n",
    "        if 'optimizer' in params.keys():\n",
    "            optimizer = params['optimizer']\n",
    "        if 'random_restarts' in params.keys():\n",
    "            random_restarts = params['random_restarts']\n",
    "\n",
    "        def call_back(weights, iteration, g):\n",
    "            ''' Actions per optimization step '''\n",
    "            objective = self.objective(weights, iteration)\n",
    "            self.objective_trace = np.vstack((self.objective_trace, objective))\n",
    "            self.weight_trace = np.vstack((self.weight_trace, weights))\n",
    "            if iteration % check_point == 0:\n",
    "                print(\"Iteration {} lower bound {}; gradient mag: {}\".format(iteration, objective, np.linalg.norm(self.gradient(weights, iteration))))\n",
    "\n",
    "        ### train with random restarts\n",
    "        optimal_obj = 1e16\n",
    "        optimal_weights = self.weights\n",
    "\n",
    "        for i in range(random_restarts):\n",
    "            if optimizer == 'adam':\n",
    "                autograd.misc.optimizers.adam(self.gradient, weights_init, step_size=step_size, num_iters=max_iteration, callback=call_back)\n",
    "            local_opt = np.min(self.objective_trace[-100:])\n",
    "            \n",
    "            if local_opt < optimal_obj:\n",
    "                opt_index = np.argmin(self.objective_trace[-100:])\n",
    "                self.weights = self.weight_trace[-100:][opt_index].reshape((1, -1))\n",
    "            weights_init = self.random.normal(0, 1, size=(1, self.D))\n",
    "\n",
    "        self.objective_trace = self.objective_trace[1:]\n",
    "        self.weight_trace = self.weight_trace[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('HW7_data.csv')\n",
    "x = data['x'].values\n",
    "y = data['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 lower bound 65.11668053773148; gradient mag: 164.73210946091572\n",
      "Iteration 100 lower bound 52.864360467566954; gradient mag: 56.95458639088454\n",
      "Iteration 200 lower bound 49.42633385370296; gradient mag: 28.31627548203755\n",
      "Iteration 300 lower bound 47.733261895623144; gradient mag: 18.311751879565843\n",
      "Iteration 400 lower bound 46.64774569354082; gradient mag: 13.47755254054697\n",
      "Iteration 500 lower bound 45.886915428058316; gradient mag: 10.503599898310592\n",
      "Iteration 600 lower bound 45.25067576634; gradient mag: 8.654932255566825\n",
      "Iteration 700 lower bound 30.562858257343013; gradient mag: 24.192575322800902\n",
      "Iteration 800 lower bound 26.977925085924852; gradient mag: 20.354176994190937\n",
      "Iteration 900 lower bound 24.278363637665738; gradient mag: 18.779125916898227\n",
      "Iteration 1000 lower bound 22.02986716940495; gradient mag: 17.427416991221943\n",
      "Iteration 1100 lower bound 20.10610040886032; gradient mag: 16.210455188665925\n",
      "Iteration 1200 lower bound 18.43436747168103; gradient mag: 15.092044558814077\n",
      "Iteration 1300 lower bound 16.967826824623163; gradient mag: 14.051620576729906\n",
      "Iteration 1400 lower bound 15.673763205688545; gradient mag: 13.07650688789188\n",
      "Iteration 1500 lower bound 14.527850196693981; gradient mag: 12.158583034329931\n",
      "Iteration 1600 lower bound 13.51104118089244; gradient mag: 11.292691333772902\n",
      "Iteration 1700 lower bound 12.607737627992938; gradient mag: 10.475901826346677\n",
      "Iteration 1800 lower bound 11.804614404003857; gradient mag: 9.707342852428724\n",
      "Iteration 1900 lower bound 11.08977327305976; gradient mag: 8.9885993566164\n"
     ]
    }
   ],
   "source": [
    "# Parameters BNN\n",
    "\n",
    "###define rbf activation function\n",
    "alpha = 1\n",
    "c = 0\n",
    "h = lambda x: np.exp(-alpha * (x - c)**2)\n",
    "\n",
    "###neural network model design choices\n",
    "width = 5\n",
    "hidden_layers = 1\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "architecture = {'width': width,\n",
    "               'hidden_layers': hidden_layers,\n",
    "               'input_dim': input_dim,\n",
    "               'output_dim': output_dim,\n",
    "               'activation_fn_type': 'rbf',\n",
    "               'activation_fn_params': 'c=0, alpha=1',\n",
    "               'activation_fn': h}\n",
    "\n",
    "#set random state to make the experiments replicable\n",
    "rand_state = 0\n",
    "random = np.random.RandomState(rand_state)\n",
    "\n",
    "#instantiate a Feedforward neural network object\n",
    "nn = Feedforward(architecture, random=random)\n",
    "\n",
    "###define design choices in gradient descent\n",
    "params = {'step_size':1e-3, \n",
    "          'max_iteration':2000, \n",
    "          'random_restarts':1}\n",
    "\n",
    "#fit my neural network to minimize MSE on the given data\n",
    "nn.fit(x.reshape((1, -1)), y.reshape((1, -1)), params)\n",
    "\n",
    "N = y.shape[0]\n",
    "D = nn.weights.shape[1]\n",
    "\n",
    "sigma_y = .5**2\n",
    "weight_noise = 5**2\n",
    "Sigma_W = weight_noise * np.eye(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters NF\n",
    "h = np.tanh\n",
    "\n",
    "# defined later\n",
    "# u = bnn_joint\n",
    "\n",
    "q_0_mu = np.array([0]*D)\n",
    "q_0_sigma = 1\n",
    "num_samples = 1000\n",
    "\n",
    "num_flows = 16\n",
    "lambda_flows = np.array([np.array([1.]*D + [0.]*D + [0.])]*num_flows)\n",
    "\n",
    "m = 10000\n",
    "step_size = .001\n",
    "\n",
    "use_adam = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples from initial distribution\n",
    "samples = np.random.multivariate_normal(q_0_mu, q_0_sigma*np.eye(D), num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda u, w, b\n",
    "\n",
    "# Flow multiple times\n",
    "def flow_samples(lambda_flows, z, h):\n",
    "    for lambda_flow in lambda_flows:\n",
    "        z = flow_once(lambda_flow, z, h)\n",
    "    return z\n",
    "\n",
    "# Flow once\n",
    "def flow_once(lambda_flow, z, h):\n",
    "    D = (lambda_flow.shape[0]-1)//2\n",
    "    z @ lambda_flow[D:2*D].reshape(-1, 1)\n",
    "    return z + h((z @ lambda_flow[D:2*D].reshape(-1, 1))+lambda_flow[-1]) @ lambda_flow[:D].reshape(1, -1)\n",
    "\n",
    "# Psi\n",
    "def psi(lambda_flow, z, h):\n",
    "    D = (lambda_flow.shape[0]-1)//2\n",
    "    return (1-h((z @ lambda_flow[D:2*D].reshape(-1, 1))+lambda_flow[-1])**2) * lambda_flow[D:2*D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate energy bound\n",
    "def energy_bound(lambda_flows, z, h, u, beta=1.):\n",
    "    D = (lambda_flows.shape[1]-1)//2\n",
    "    initial_exp = np.mean(np.log(sp.stats.norm.pdf(z, loc=q_0_mu, scale=np.sqrt(q_0_sigma))))\n",
    "    joint_exp = beta*np.mean(np.log(u(flow_samples(lambda_flows, z, h))))\n",
    "    flow_exp = 0.\n",
    "    for lambda_flow in lambda_flows:\n",
    "        flow_exp += np.mean(np.log(np.abs(1 + np.dot(psi(lambda_flow, z, h), lambda_flow[:D]))))\n",
    "        z = flow_once(lambda_flow, z, h)\n",
    "    return initial_exp - joint_exp - flow_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joint_exp(lambda_flows, z, h):\n",
    "    return np.mean(np.log(u(flow_samples(lambda_flows, z, h))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flow_exp(lambda_flows, z, h):\n",
    "    D = (lambda_flows.shape[1]-1)//2\n",
    "    flow_exp = 0\n",
    "    for lambda_flow in lambda_flows:\n",
    "        flow_exp += np.mean(np.log(np.abs(1 + np.dot(psi(lambda_flow, z, h), lambda_flow[:D]))))\n",
    "        z = flow_once(lambda_flow, z, h)\n",
    "        \n",
    "    return flow_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_exp(z):\n",
    "    return np.mean(np.log(sp.stats.norm.pdf(z, loc=q_0_mu, scale=np.sqrt(q_0_sigma))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_energy_bound = autograd.grad(energy_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta(i):\n",
    "#     return min(1, 0.01+i/10000)\n",
    "    return 2+i/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Cooper\n",
    "start = time.time()\n",
    "def callback(x, i, g):\n",
    "#     samples_flowed = flow_samples(x, samples, h)\n",
    "    \n",
    "#     # Debug\n",
    "#     initial_hist[i] = get_initial_exp(samples)\n",
    "#     energy_hist[i] = energy_bound(x, samples, h, u)\n",
    "#     joint_hist[i] = get_joint_exp(x, samples, h)\n",
    "#     flow_hist[i] = get_flow_exp(x, samples, h)\n",
    "#     lambda_hist[i] = lambda_flows\n",
    "    \n",
    "#     # Plot\n",
    "#     if i % 1000 == 0:\n",
    "#         fig, ax = plt.subplots()\n",
    "#         ax.contourf(X, Y, U_z, cmap='Reds', levels=15)\n",
    "#         ax.scatter(samples_flowed[:, 0], samples_flowed[:, 1], alpha=.5)\n",
    "#         plt.show()\n",
    "\n",
    "    if(i%10 == 0):\n",
    "        left = '['\n",
    "        right = ']'\n",
    "        eq = '=' * int(20*i/m)\n",
    "        blank = ' ' * int(np.ceil(20*(1 - i/m)))\n",
    "        sys.stdout.write(\"{0}{1}{2}{3}  {4:.3f}%  {5:.2f}s\\r\".format(\n",
    "                         left, eq, blank, right, 100*i/m, time.time()-start))\n",
    "        sys.stdout.flush()\n",
    "    if(i==(m-1)):\n",
    "        sys.stdout.write(\"{}\\r\".format(' '*50))\n",
    "        sys.stdout.flush()\n",
    "        print(\"[{}]  100%  {}\".format(20*'=', time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bnn_nf(Sigma_W, y_train, x_train, use_adam, lambda_flows, forward):\n",
    "    Sigma_W_inv = np.linalg.inv(Sigma_W)\n",
    "    Sigma_W_det = np.linalg.det(Sigma_W)\n",
    "\n",
    "    #define the log prior on the model parameters\n",
    "    def log_prior(W):\n",
    "    #         print('W_prior', W.shape)\n",
    "        constant_W = -0.5 * (D * np.log(2 * np.pi) + np.log(Sigma_W_det))\n",
    "        exponential_W = -0.5 * np.diag(np.dot(np.dot(W, Sigma_W_inv), W.T))\n",
    "        log_p_W = constant_W + exponential_W\n",
    "        return log_p_W\n",
    "\n",
    "    #define the log likelihood\n",
    "    def log_lklhd(W):\n",
    "    #         print('W_lklhd', W.shape)\n",
    "        S = W.shape[0]\n",
    "        constant = (-np.log(sigma_y) - 0.5 * np.log(2 * np.pi)) * N\n",
    "        exponential = -0.5 * sigma_y**-2 * np.sum((y_train.reshape((1, 1, N)) - forward(W, x_train))**2, axis=2).flatten()\n",
    "        return constant + exponential\n",
    "\n",
    "    #define the log joint density\n",
    "    def bnn_joint(w):\n",
    "        return log_lklhd(w) + log_prior(w)\n",
    "    \n",
    "    u = bnn_joint\n",
    "    \n",
    "    if use_adam:\n",
    "        grad_energy_bound_lambda = lambda params, i : grad_energy_bound(params, samples, h, u, get_beta(i))\n",
    "        lambda_flows = autograd.misc.optimizers.adam(grad_energy_bound_lambda, lambda_flows,\n",
    "                                                     callback=callback, num_iters=m, step_size=step_size)\n",
    "    else:\n",
    "        for i in tqdm(range(m)):\n",
    "            gradient = grad_energy_bound(lambda_flows, samples, h, get_beta(i))\n",
    "            lambda_flows -= step_size*gradient\n",
    "\n",
    "            callback(lambda_flows, i, gradient)\n",
    "            \n",
    "    return lambda_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                    ]  0.000%  0.07s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elisionducoeur/anaconda3/lib/python3.7/site-packages/autograd/tracer.py:48: RuntimeWarning: invalid value encountered in log\n",
      "  return f_raw(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================]  100%  679.392635345459    \n"
     ]
    }
   ],
   "source": [
    "initial_hist = np.empty(m)\n",
    "energy_hist = np.empty(m)\n",
    "joint_hist = np.empty(m)\n",
    "flow_hist = np.empty(m)\n",
    "lambda_hist = np.empty((m, *lambda_flows.shape))\n",
    "\n",
    "lambda_flows = bnn_nf(Sigma_W, y.reshape((1, -1)), x.reshape((1, -1)), use_adam, lambda_flows, nn.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f68b7fde410>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "posterior_sample_size = 100\n",
    "x_test = np.linspace(-8, 8, 100)\n",
    "\n",
    "#sample from the posterior\n",
    "posterior_samples = flow_samples(lambda_flows, np.random.multivariate_normal(q_0_mu, q_0_sigma*np.eye(D), posterior_sample_size), h)\n",
    "\n",
    "#predict on x_test\n",
    "y_pred = nn.forward(posterior_samples, x_test.reshape((1, -1))).reshape(posterior_sample_size, len(x_test))\n",
    "# y_pred = y_pred + np.random.normal(0, sigma_y**0.5, size=(posterior_sample_size, len(x_test)))\n",
    "\n",
    "#Gaussian log pdf\n",
    "gaussian_log_pdf = lambda mu, sigma_sq, x: -0.5 * (np.log(2 * np.pi * sigma_sq) + (x - mu)**2 / sigma_sq)\n",
    "\n",
    "#compute the 95 percentiles of the posterior predictives\n",
    "ub_bayes = np.percentile(y_pred, 97.5, axis=0)\n",
    "lb_bayes = np.percentile(y_pred, 2.5, axis=0)\n",
    "\n",
    "#visualize the posterior predictive distribution\n",
    "plt.scatter(x, y, color='red', s=10, alpha=0.5, label='train data')\n",
    "plt.fill_between(x_test, ub_bayes, lb_bayes, color='green', alpha=0.2)\n",
    "plt.title('NF variational approximation of the posterior')\n",
    "plt.legend(loc='best')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
